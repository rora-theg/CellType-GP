"""
celltype_gp_models.py
---------------------
æ¨¡å—åŠŸèƒ½ï¼š
    åŸºäºä¸åŒæ¨¡å‹æ–¹æ³•è®¡ç®—ç»†èƒç±»å‹ç‰¹å¼‚æ€§åŸºå› ç¨‹åºè´¡çŒ® (Y_tps)
    å¹¶è½¬æ¢ä¸ºä¸ truth_result å¯¹åº”çš„å®½æ ¼å¼ç»“æœè¡¨ã€‚

è¾“å…¥è¦æ±‚ï¼š
    npz æ–‡ä»¶ä¸­åŒ…å«ï¼š
        - visium_score: (P, S)
        - spot_cluster_fraction_matrix: (S, T)
        - coords: (S, 2)
        - spot_names, celltype_names, program_names
"""

import numpy as np
import pandas as pd
import torch
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from scipy.spatial.distance import cdist


# ====================================================
# ğŸ§  æ ¸å¿ƒå‡½æ•°ï¼šä¸åŒè®¡ç®—æ–¹æ³•
# ====================================================

# ç”±äºç•™ä¸€æ³•åœ¨æ•°å€¼ä¸Šç›¸å‡ä¸¤æ¬¡ç›¸è¿‘é¢„æµ‹ï¼Œè¯¯å·®è¢«ä¸¥é‡æŠµæ¶ˆï¼Œå»ºè®®å¼ƒç”¨ delta_loo æˆ–æ”¹ä¸ºç›¸å¯¹å·®å®šä¹‰ï¼Œä¸»ç”¨ residual_vectorized åš ctGP åˆ†è§£ã€‚
# def delta_loo(Y, X):
#     """è´¡çŒ®å·®å€¼æ³• (Y_tps = y_full - y_loo)"""
#     P, S = Y.shape
#     S2, T = X.shape
#     assert S == S2
#     Y_tps = torch.zeros((T, P, S))

#     X_scaled = (X - X.mean(0)) / (X.std(0) + 1e-6)
#     ridge = Ridge(alpha=0.1)

#     for p in range(P):
#         y = Y[p, :].numpy()
#         ridge.fit(X_scaled.numpy(), y)
#         y_full = ridge.predict(X_scaled.numpy())
#         for t in range(T):
#             X_loo = np.delete(X_scaled.numpy(), t, axis=1)
#             ridge.fit(X_loo, y)
#             y_loo = ridge.predict(X_loo)
#             Y_tps[t, p, :] = torch.tensor(y_full - y_loo)
#     return Y_tps


def residual_vectorized(Y, X):
    P, S = Y.shape
    S2, T = X.shape
    assert S == S2
    X_scaled = (X - X.mean(0)) / (X.std(0) + 1e-6)

    ridge = Ridge(alpha=0.1)
    ridge.fit(X_scaled, Y.T)   
    coefs = torch.tensor(ridge.coef_.T, dtype=torch.float32)  # (T, P)
    X_scaled = torch.tensor(X_scaled, dtype=torch.float32)
    Y = torch.tensor(Y, dtype=torch.float32)

    Y_tps = torch.empty((T, P, S))
    for t in range(T):
        mask = torch.ones(T, dtype=torch.bool); mask[t] = False
        X_other = X_scaled[:, mask]
        beta_other = coefs[mask, :]
        Y_tps[t] = (Y.T - X_other @ beta_other).T
    return Y_tps


# ç©ºé—´ä¾èµ–æ€§å»ºæ¨¡æ³•ï¼ˆå–æ¶ˆï¼‰

# ====================================================
# ğŸ§¾ å·¥å…·å‡½æ•°
# ====================================================

def Ytps_to_wide_df(Y_tps, spot_names, celltype_names, program_names):
    """æŠŠ Y_tps è½¬ä¸º truth_result æ ·å¼çš„å®½è¡¨æ ¼"""
    T, P, S = Y_tps.shape
    Y_tps_np = Y_tps.permute(2, 0, 1).reshape(S, T * P).numpy()
    columns = [f"{ct}+{pg}" for ct in celltype_names for pg in program_names]
    return pd.DataFrame(Y_tps_np, index=spot_names, columns=columns)


# ====================================================
# ğŸš€ ä¸»å‡½æ•°å…¥å£
# ====================================================

def run_model(npz_path, method="vectorized", save_path="train_result.csv"):
    data = np.load(npz_path, allow_pickle=True)
    Y = torch.tensor(data["visium_score"], dtype=torch.float32)  # (P, S)
    X = torch.tensor(data["spot_cluster_fraction_matrix"], dtype=torch.float32)  # (S, T)
    coords = data["coords"] # è‹¥éœ€ç©ºé—´ä¾èµ–æ€§å»ºæ¨¡ï¼Œåˆ™å› å¯¼å…¥coords
    spot_names = data["spot_names"]
    celltype_names = data["celltype_names"]
    program_names = data["program_names"]

    if method == "delta":
        Y_tps = delta_loo(Y, X)
    elif method == "vectorized":
        Y_tps = residual_vectorized(Y, X)
    else:
        raise ValueError("method å¿…é¡»æ˜¯ ['delta', 'vectorized'] ä¹‹ä¸€")

    df = Ytps_to_wide_df(Y_tps, spot_names, celltype_names, program_names)
    df.to_csv(save_path)
    print(f"âœ… å·²ä¿å­˜ç»“æœåˆ° {save_path}ï¼Œå½¢çŠ¶ {df.shape}")
    return df



# ====================================================
# ğŸ§­ å‘½ä»¤è¡Œå…¥å£ï¼ˆå¯é€‰ï¼‰
# ====================================================
if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Run celltype-GP model.")
    parser.add_argument("--input", type=str, required=True, help="Path to npz file")
    parser.add_argument("--method", type=str, default="vectorized", help="Method name")
    parser.add_argument("--save", type=str, default="train_result.csv", help="Output path")
    args = parser.parse_args()

    run_model(args.input, args.method, args.save)

